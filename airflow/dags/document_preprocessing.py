# DAG 1: Document Preprocessing
# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏–∑ PDF —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Docling + OCR + Tabula

from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator
from airflow.utils.decorators import apply_defaults

# –ò–º–ø–æ—Ä—Ç –Ω–∞—à–∏—Ö –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤
from shared_utils import (
    DocumentProcessorOperator,
    SharedUtils,
    NotificationUtils,
    ConfigUtils
)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è DAG
DEFAULT_ARGS = {
    'owner': 'pdf-converter',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
}

# –°–æ–∑–¥–∞–Ω–∏–µ DAG
dag = DAG(
    'document_preprocessing',
    default_args=DEFAULT_ARGS,
    description='DAG 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏–∑ PDF –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤',
    schedule_interval=None,  # –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –ø–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—é
    max_active_runs=3,
    catchup=False,
    tags=['pdf-converter', 'preprocessing', 'docling', 'ocr']
)

def validate_input_task(**context):
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω–æ–≥–æ PDF —Ñ–∞–π–ª–∞"""
    input_file = context['dag_run'].conf.get('input_file')
    
    if not input_file:
        raise ValueError("–ù–µ —É–∫–∞–∑–∞–Ω –≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª")
    
    if not SharedUtils.validate_input_file(input_file):
        raise ValueError(f"–ù–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–π —Ñ–∞–π–ª: {input_file}")
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞
    import os
    file_stats = os.stat(input_file)
    
    metadata = {
        'file_path': input_file,
        'file_size_bytes': file_stats.st_size,
        'file_size_mb': round(file_stats.st_size / (1024*1024), 2),
        'file_name': os.path.basename(input_file),
        'validation_timestamp': datetime.now().isoformat()
    }
    
    print(f"‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –ø—Ä–æ–π–¥–µ–Ω–∞: {metadata}")
    return metadata

def prepare_processing_config(**context):
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    dag_conf = context['dag_run'].conf
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é + –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    processing_config = {
        # OCR –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        'enable_ocr': dag_conf.get('enable_ocr', True),
        'ocr_languages': dag_conf.get('ocr_languages', 'chi_sim,chi_tra,eng,rus'),
        'ocr_engine_primary': 'paddleocr',
        'ocr_engine_secondary': 'tesseract',
        
        # Docling –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        'docling_device': dag_conf.get('docling_device', 'cuda'),
        'layout_analysis': True,
        'structure_detection': True,
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        'extract_tables': dag_conf.get('extract_tables', True),
        'extract_images': dag_conf.get('extract_images', True),
        'extract_formulas': dag_conf.get('extract_formulas', True),
        'extract_code_blocks': True,
        
        # Tabula-Py –¥–ª—è —Ç–∞–±–ª–∏—Ü
        'tabula_enabled': True,
        'tabula_pages': 'all',
        'tabula_lattice': True,
        'tabula_stream': True,
        
        # –ö–∞—á–µ—Å—Ç–≤–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
        'quality_level': dag_conf.get('quality_level', 'high'),
        'preserve_formatting': True,
        'preserve_structure': dag_conf.get('preserve_structure', True),
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è –∫–∏—Ç–∞–π—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        'chinese_optimization': True,
        'traditional_simplified_conversion': True,
        
        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        'max_processing_time': 1800,  # 30 –º–∏–Ω—É—Ç
        'memory_limit': '4G'
    }
    
    print(f"üìã –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_config}")
    return processing_config

# –ó–∞–¥–∞—á–∞ 1: –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
validate_input = PythonOperator(
    task_id='validate_input_file',
    python_callable=validate_input_task,
    dag=dag
)

# –ó–∞–¥–∞—á–∞ 2: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
prepare_config = PythonOperator(
    task_id='prepare_processing_config',
    python_callable=prepare_processing_config,
    dag=dag
)

# –ó–∞–¥–∞—á–∞ 3: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ Document Processor
extract_content = DocumentProcessorOperator(
    task_id='extract_content',
    input_file_path="{{ dag_run.conf['input_file'] }}",
    processing_options="{{ task_instance.xcom_pull(task_ids='prepare_processing_config') }}",
    timeout=1800,  # 30 –º–∏–Ω—É—Ç
    dag=dag
)

def analyze_extraction_results(**context):
    """–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
    extraction_data = context['task_instance'].xcom_pull(task_ids='extract_content')
    
    if not extraction_data:
        raise ValueError("–ù–µ –ø–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –æ—Ç Document Processor")
    
    # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
    text_length = len(extraction_data.get('extracted_text', ''))
    tables_count = len(extraction_data.get('tables', []))
    images_count = len(extraction_data.get('images', []))
    
    analysis = {
        'extraction_quality': {
            'text_extracted': text_length > 0,
            'text_length': text_length,
            'tables_found': tables_count,
            'images_found': images_count,
            'has_structure': bool(extraction_data.get('document_structure'))
        },
        'processing_stats': extraction_data.get('processing_stats', {}),
        'readiness_for_next_dag': True
    }
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
    if text_length < 100:
        print("‚ö†Ô∏è –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: –ò–∑–≤–ª–µ—á–µ–Ω–æ –º–∞–ª–æ —Ç–µ–∫—Å—Ç–∞")
        analysis['readiness_for_next_dag'] = False
    
    if tables_count == 0 and 'table' in extraction_data.get('extracted_text', '').lower():
        print("‚ö†Ô∏è –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: –í–æ–∑–º–æ–∂–Ω–æ –ø—Ä–æ–ø—É—â–µ–Ω—ã —Ç–∞–±–ª–∏—Ü—ã")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ DAG
    dag_2_input = {
        'extracted_content': extraction_data,
        'analysis': analysis,
        'source_file': context['dag_run'].conf.get('input_file'),
        'processing_timestamp': datetime.now().isoformat()
    }
    
    print(f"üìä –ê–Ω–∞–ª–∏–∑ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è: {analysis}")
    return dag_2_input

# –ó–∞–¥–∞—á–∞ 4: –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
analyze_results = PythonOperator(
    task_id='analyze_extraction_results',
    python_callable=analyze_extraction_results,
    dag=dag
)

def save_intermediate_results(**context):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    dag_2_input = context['task_instance'].xcom_pull(task_ids='analyze_extraction_results')
    timestamp = context['dag_run'].conf.get('timestamp', int(datetime.now().timestamp()))
    filename = context['dag_run'].conf.get('filename', 'unknown.pdf')
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ DAG
    intermediate_path = f"/app/temp/dag1_results_{timestamp}.json"
    
    import json
    import os
    
    os.makedirs(os.path.dirname(intermediate_path), exist_ok=True)
    
    with open(intermediate_path, 'w', encoding='utf-8') as f:
        json.dump(dag_2_input, f, ensure_ascii=False, indent=2)
    
    # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞
    os.chown(intermediate_path, 1000, 1000)
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è DAG 2
    next_dag_config = {
        'intermediate_file': intermediate_path,
        'original_config': context['dag_run'].conf,
        'dag1_completed': True,
        'ready_for_dag2': dag_2_input['analysis']['readiness_for_next_dag']
    }
    
    print(f"üíæ –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {intermediate_path}")
    return next_dag_config

# –ó–∞–¥–∞—á–∞ 5: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
save_results = PythonOperator(
    task_id='save_intermediate_results',
    python_callable=save_intermediate_results,
    dag=dag
)

def notify_completion(**context):
    """–£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ DAG 1"""
    results = context['task_instance'].xcom_pull(task_ids='save_intermediate_results')
    dag_run_id = context['dag_run'].run_id
    
    if results and results.get('ready_for_dag2'):
        message = f"""
        ‚úÖ DAG 1 (Document Preprocessing) —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω
        
        Run ID: {dag_run_id}
        –§–∞–π–ª: {context['dag_run'].conf.get('filename', 'unknown')}
        
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:
        - –¢–µ–∫—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω: ‚úÖ
        - –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {results.get('intermediate_file')}
        - –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –¥–ª—è DAG 2: {'‚úÖ –î–∞' if results.get('ready_for_dag2') else '‚ùå –ù–µ—Ç'}
        
        –°–ª–µ–¥—É—é—â–∏–π —ç—Ç–∞–ø: Content Transformation (DAG 2)
        """
    else:
        message = f"""
        ‚ùå DAG 1 (Document Preprocessing) –∑–∞–≤–µ—Ä—à–µ–Ω —Å –ø—Ä–æ–±–ª–µ–º–∞–º–∏
        
        Run ID: {dag_run_id}
        –ù–µ–æ–±—Ö–æ–¥–∏–º–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
        """
    
    print(message)
    
    # –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ —Å–∏—Å—Ç–µ–º—É –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
    NotificationUtils.send_success_notification(context, results or {})

# –ó–∞–¥–∞—á–∞ 6: –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏
notify_task = PythonOperator(
    task_id='notify_completion',
    python_callable=notify_completion,
    dag=dag
)

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –∑–∞–¥–∞—á
validate_input >> prepare_config >> extract_content >> analyze_results >> save_results >> notify_task

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫
def handle_failure(context):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –≤ DAG"""
    NotificationUtils.send_failure_notification(context, context.get('exception'))

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ –æ—à–∏–±–æ–∫ –∫–æ –≤—Å–µ–º –∑–∞–¥–∞—á–∞–º
for task in dag.tasks:
    task.on_failure_callback = handle_failure