#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üöÄ vLLM Translator Service v2.0 (–ò–°–ü–†–ê–í–õ–ï–ù–û)
=====================================================================
–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –º–æ–¥—É–ª—å –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ ollama-translator
–ê–¥–∞–ø—Ç–∞—Ü–∏—è –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å vLLM API –≤–º–µ—Å—Ç–æ Ollama
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å PDF Converter Pipeline v2.0

–û–°–ù–û–í–ù–´–ï –ò–ó–ú–ï–ù–ï–ù–ò–Ø:
‚úÖ –ó–∞–º–µ–Ω–∞ Ollama API –Ω–∞ vLLM OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π API
‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ Qwen3-30B-A3B-Instruct-2507
‚úÖ –û—Ç–∫–ª—é—á–µ–Ω–∏–µ thinking —Ä–µ–∂–∏–º–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –∏ –∫–æ–º–∞–Ω–¥
‚úÖ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π
"""

import os
import re
import time
import json
import hashlib
import logging
import asyncio
from datetime import datetime
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass, field

# FastAPI –∏ –≤–µ–±-—Å–µ—Ä–≤–µ—Ä
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn

# HTTP –∫–ª–∏–µ–Ω—Ç—ã
import aiohttp
import requests

# –ü—Ä–æ–≥—Ä–µ—Å—Å –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
from tqdm.asyncio import tqdm as async_tqdm
import prometheus_client
from prometheus_client import Counter, Histogram, Gauge

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ==============================================
# üîß –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ò –ù–ê–°–¢–†–û–ô–ö–ò v2.0
# ==============================================

# vLLM API –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (–ò–°–ü–†–ê–í–õ–ï–ù–û)
VLLM_API_URL = os.getenv('VLLM_SERVER_URL', 'http://vllm-server:8000')
VLLM_API_ENDPOINT = "/v1/chat/completions"
TRANSLATION_MODEL = os.getenv('VLLM_TRANSLATION_MODEL', 'Qwen/Qwen3-30B-A3B-Instruct-2507')

# API –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
API_TEMPERATURE = float(os.getenv('VLLM_TEMPERATURE', '0.1'))
API_MAX_TOKENS = int(os.getenv('VLLM_MAX_TOKENS', '4096'))
API_TOP_P = float(os.getenv('VLLM_TOP_P', '0.9'))
API_TOP_K = int(os.getenv('VLLM_TOP_K', '50'))

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
REQUEST_TIMEOUT = int(os.getenv('REQUEST_TIMEOUT', '600'))
INTER_REQUEST_DELAY = float(os.getenv('INTER_REQUEST_DELAY', '0.2'))
DISABLE_THINKING = os.getenv('DISABLE_THINKING', 'true').lower() == 'true'

# –ë–∞—Ç—á–∏–Ω–≥
BATCH_SIZE_HEADERS = int(os.getenv('BATCH_SIZE_HEADERS', '4'))
BATCH_SIZE_TABLES = int(os.getenv('BATCH_SIZE_TABLES', '3'))
BATCH_SIZE_COMMANDS = int(os.getenv('BATCH_SIZE_COMMANDS', '2'))
BATCH_SIZE_TEXT = int(os.getenv('BATCH_SIZE_TEXT', '6'))
BATCH_SIZE_MIXED = int(os.getenv('BATCH_SIZE_MIXED', '4'))

# –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ
ENABLE_CACHING = os.getenv('ENABLE_CACHING', 'true').lower() == 'true'
CACHE_SIZE_LIMIT = int(os.getenv('CACHE_SIZE_LIMIT', '5000'))
translation_cache = {}

# ==============================================
# üìö –°–õ–û–í–ê–†–¨ –¢–ï–•–ù–ò–ß–ï–°–ö–ò–• –¢–ï–†–ú–ò–ù–û–í v2.0
# ==============================================

TECHNICAL_TERMINOLOGY = {
    # Brand names (–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û!)
    "ÈóÆÂ§©": "WenTian",
    "ËÅîÊÉ≥ÈóÆÂ§©": "Lenovo WenTian", 
    "Â§©Êìé": "ThinkSystem",
    "AnyBay": "AnyBay",
    
    # Processors
    "Ëá≥Âº∫": "Xeon",
    "ÂèØÊâ©Â±ïÂ§ÑÁêÜÂô®": "Scalable Processors",
    "Ëã±ÁâπÂ∞î": "Intel",
    "Â§ÑÁêÜÂô®": "Processor",
    "ÂÜÖÊ†∏": "Core",
    "Á∫øÁ®ã": "Thread",
    "ÁùøÈ¢ë": "Turbo Boost",
    
    # Memory and storage
    "ÂÜÖÂ≠ò": "Memory",
    "Â≠òÂÇ®": "Storage", 
    "Á°¨Áõò": "Drive",
    "Âõ∫ÊÄÅÁ°¨Áõò": "SSD",
    "Êú∫Ê¢∞Á°¨Áõò": "HDD",
    "ÁÉ≠ÊèíÊãî": "Hot-swap",
    "ÂÜó‰Ωô": "Redundancy",
    "ËÉåÊùø": "Backplane",
    "ÊâòÊû∂": "Tray",
    
    # Network
    "‰ª•Â§™ÁΩë": "Ethernet",
    "ÂÖâÁ∫§": "Fiber",
    "Â∏¶ÂÆΩ": "Bandwidth",
    "Âª∂Ëøü": "Latency",
    "ÁΩëÂç°": "Network Adapter",
    
    # Cooling
    "È£éÂÜ∑": "Air cooling",
    "Ê∂≤ÂÜ∑": "Liquid cooling",
    "Êï£ÁÉ≠": "Cooling",
    "È£éÊâá": "Fan",
    "Êï£ÁÉ≠Âô®": "Heatsink",
    
    # Form factors
    "Ëã±ÂØ∏": "inch",
    "Êú∫Êû∂": "Rack",
    "ÊèíÊßΩ": "Slot",
    "ËΩ¨Êé•Âç°": "Riser Card",
    
    # Power
    "ÁîµÊ∫ê": "Power Supply",
    "ÈìÇÈáë": "Platinum", 
    "ÈíõÈáë": "Titanium",
    "CRPS": "CRPS",
    
    # Components
    "ËäØÁâáÁªÑ": "Chipset",
    "ÊéßÂà∂Âô®": "Controller",
    "ÈÄÇÈÖçÂô®": "Adapter",
    "ÂÖâÈ©±": "Optical Drive"
}

# –†—É—Å—Å–∫–∞—è —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è
TECHNICAL_TERMINOLOGY_RU = {
    "ÈóÆÂ§©": "WenTian",
    "ËÅîÊÉ≥ÈóÆÂ§©": "Lenovo WenTian",
    "Ëá≥Âº∫": "Xeon",
    "ÂèØÊâ©Â±ïÂ§ÑÁêÜÂô®": "Scalable –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—ã",
    "Ëã±ÁâπÂ∞î": "Intel",
    "Â§ÑÁêÜÂô®": "–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä",
    "ÂÜÖÊ†∏": "—è–¥—Ä–æ",
    "Á∫øÁ®ã": "–ø–æ—Ç–æ–∫",
    "ÂÜÖÂ≠ò": "–ø–∞–º—è—Ç—å",
    "Â≠òÂÇ®": "—Ö—Ä–∞–Ω–∏–ª–∏—â–µ",
    "Á°¨Áõò": "–¥–∏—Å–∫",
    "Âõ∫ÊÄÅÁ°¨Áõò": "SSD",
    "Êú∫Ê¢∞Á°¨Áõò": "HDD",
    "ÁÉ≠ÊèíÊãî": "–≥–æ—Ä—è—á–∞—è –∑–∞–º–µ–Ω–∞",
    "ÂÜó‰Ωô": "—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–∏–µ",
    "ÊâòÊû∂": "–ª–æ—Ç–æ–∫",
    "‰ª•Â§™ÁΩë": "Ethernet",
    "Â∏¶ÂÆΩ": "–ø—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å",
    "Âª∂Ëøü": "–∑–∞–¥–µ—Ä–∂–∫–∞",
    "È£éÂÜ∑": "–≤–æ–∑–¥—É—à–Ω–æ–µ –æ—Ö–ª–∞–∂–¥–µ–Ω–∏–µ",
    "Ê∂≤ÂÜ∑": "–∂–∏–¥–∫–æ—Å—Ç–Ω–æ–µ –æ—Ö–ª–∞–∂–¥–µ–Ω–∏–µ",
    "Êï£ÁÉ≠Âô®": "—Ä–∞–¥–∏–∞—Ç–æ—Ä",
    "Êú∫Êû∂": "—Å—Ç–æ–π–∫–∞",
    "ÊèíÊßΩ": "—Å–ª–æ—Ç",
    "ÁîµÊ∫ê": "–±–ª–æ–∫ –ø–∏—Ç–∞–Ω–∏—è",
    "ÈìÇÈáë": "–ø–ª–∞—Ç–∏–Ω–æ–≤—ã–π",
    "ÈíõÈáë": "—Ç–∏—Ç–∞–Ω–æ–≤—ã–π"
}

# ==============================================
# üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ò –ú–û–ù–ò–¢–û–†–ò–ù–ì v2.0
# ==============================================

@dataclass
class TranslationStats:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ —Å Prometheus –º–µ—Ç—Ä–∏–∫–∞–º–∏"""
    total_lines: int = 0
    api_requests: int = 0
    cache_hits: int = 0
    cache_misses: int = 0
    chinese_remaining_start: int = 0
    chinese_remaining_end: int = 0
    fixes_attempted: int = 0
    fixes_successful: int = 0
    processing_time: float = 0
    start_time: float = field(default_factory=time.time)
    quality_checks: List[Dict] = field(default_factory=list)
    technical_terms_fixed: int = 0

    def add_quality_check(self, original: str, translated: str, target_lang: str) -> dict:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞"""
        validation = validate_technical_translation(original, translated, target_lang)
        self.quality_checks.append(validation)
        return validation

    def get_average_quality(self) -> float:
        """–°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª –∫–∞—á–µ—Å—Ç–≤–∞"""
        if not self.quality_checks:
            return 0
        return sum(check['quality_score'] for check in self.quality_checks) / len(self.quality_checks)

# Prometheus –º–µ—Ç—Ä–∏–∫–∏
translation_requests = Counter('translation_requests_total', 'Total translation requests')
translation_duration = Histogram('translation_duration_seconds', 'Translation duration')
translation_quality = Gauge('translation_quality_score', 'Average translation quality score')
cache_hit_ratio = Gauge('cache_hit_ratio', 'Cache hit ratio')

# ==============================================
# üß† –ü–†–û–ú–ü–¢–´ v2.0 (–û–¢–ö–õ–Æ–ß–ï–ù–ò–ï THINKING)
# ==============================================

def get_system_prompt(source_lang_name: str, target_lang_name: str) -> str:
    """–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ–º thinking —Ä–µ–∂–∏–º–∞"""
    return f"""–í—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø–µ—Ä–µ–≤–æ–¥—É —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å–µ—Ä–≤–µ—Ä–Ω–æ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è.

–û–°–ù–û–í–ù–ê–Ø –ó–ê–î–ê–ß–ê: –ü–µ—Ä–µ–≤–æ–¥–∏—Ç–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ–∫—Å—Ç—ã —Å {source_lang_name} –Ω–∞ {target_lang_name} —è–∑—ã–∫.

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê:
1. –¢–û–õ–¨–ö–û –≥–æ—Ç–æ–≤—ã–π –ø–µ—Ä–µ–≤–æ–¥, –ë–ï–ó –ø–æ—è—Å–Ω–µ–Ω–∏–π –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
2. –ù–ò–ö–û–ì–î–ê –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ—Ä–∞–∑—ã "–í–æ—Ç –ø–µ—Ä–µ–≤–æ–¥", "Here is translation"
3. –ù–ï –¥–æ–±–∞–≤–ª—è–π—Ç–µ —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏—è –≤ —Ç–µ–≥–∞—Ö <–¥—É–º–∞—é>, –∏–ª–∏ –ª—é–±—ã—Ö –¥—Ä—É–≥–∏—Ö
4. –°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ –í–°–ï —á–∏—Å–ª–∞, –∫–æ–¥—ã, —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¢–û–ß–ù–û
5. –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ thinking —Ä–µ–∂–∏–º - –æ—Ç–≤–µ—á–∞–π—Ç–µ —Å—Ä–∞–∑—É –∏ –∫—Ä–∞—Ç–∫–æ

–ë–†–ï–ù–î–´ (–ù–ï –ú–ï–ù–Ø–¢–¨!):
- "ÈóÆÂ§©" –í–°–ï–ì–î–ê ‚Üí "WenTian"
- "ËÅîÊÉ≥ÈóÆÂ§©" –í–°–ï–ì–î–ê ‚Üí "Lenovo WenTian"
- –°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ: Intel, Xeon, PCIe, DDR5, NVMe, SAS, SATA

–ö–û–ú–ê–ù–î–´ –ù–ï –ü–ï–†–ï–í–û–î–ò–¢–¨:
- IPMI: chassis, power, mc, sensor, sel, sdr, fru
- API: get, set, list, status, activate, deactivate
- Hex –∫–æ–¥—ã: 0x30, 0x02
- –ê–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã: GPU, CPU, SSD, HDD, RAID, BMC

–§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–ï:
- –°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É Markdown —Ç–∞–±–ª–∏—Ü –¢–û–ß–ù–û
- –ù–ï –∏–∑–º–µ–Ω—è–π—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤
- –°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ HTML —Ç–µ–≥–∏ –∏ –æ—Ç—Å—Ç—É–ø—ã

–í—ã–≤–æ–¥–∏—Ç–µ –¢–û–õ–¨–ö–û {target_lang_name} –ø–µ—Ä–µ–≤–æ–¥ –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞!"""

def get_user_prompt(text_to_translate: str, source_lang_name: str, target_lang_name: str) -> str:
    """–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç"""
    return f"""–ü–µ—Ä–µ–≤–µ–¥–∏—Ç–µ —ç—Ç–æ—Ç {source_lang_name} —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Ç–µ–∫—Å—Ç –Ω–∞ {target_lang_name} —è–∑—ã–∫:

{text_to_translate}"""

# ==============================================
# üîç –í–ê–õ–ò–î–ê–¶–ò–Ø –ö–ê–ß–ï–°–¢–í–ê v2.0
# ==============================================

def validate_technical_translation(original: str, translated: str, target_lang: str) -> dict:
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –ø–µ—Ä–µ–≤–æ–¥–∞"""
    quality_score = 100
    issues = []

    # 1. –ö–∏—Ç–∞–π—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã
    chinese_count = len(re.findall(r'[\u4e00-\u9fff]', translated))
    if chinese_count > 0:
        quality_score -= min(50, chinese_count * 3)
        issues.append(f"–û—Å—Ç–∞–ª–∏—Å—å –∫–∏—Ç–∞–π—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã: {chinese_count}")

    # 2. –†–∞–∑–º—ã—à–ª–µ–Ω–∏—è –∏ thinking
    thinking_patterns = [
        r'[–•—Ö]–æ—Ä–æ—à–æ[,\s]*–º–Ω–µ', r'[–°—Å]–Ω–∞—á–∞–ª–∞ –ø–æ—Å–º–æ—Ç—Ä', r'Let me', r'First I',
        r'[–í–≤]–æ—Ç –ø–µ—Ä–µ–≤–æ–¥', r'Here is', r'[–ù–Ω]–∏–∂–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω',
        r'<–¥—É–º–∞—é>', r'</–¥—É–º–∞—é>', r'<thinking>', r'</thinking>'
    ]
    
    thinking_count = sum(len(re.findall(pattern, translated)) for pattern in thinking_patterns)
    if thinking_count > 0:
        quality_score -= min(30, thinking_count * 10)
        issues.append(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏—è: {thinking_count}")

    # 3. –í–ê–ñ–ù–û: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏ –ø–µ—Ä–µ–≤–æ–¥–∞ –±—Ä–µ–Ω–¥–æ–≤
    if "ÈóÆÂ§©" in original:
        if "WenTian" not in translated:
            quality_score -= 20
            issues.append("–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ –±—Ä–µ–Ω–¥–∞ ÈóÆÂ§©")

    # 4. –¢–∞–±–ª–∏—Ü—ã
    orig_table_rows = len(re.findall(r'^\|.*\|$', original, re.MULTILINE))
    trans_table_rows = len(re.findall(r'^\|.*\|$', translated, re.MULTILINE))
    if orig_table_rows > 0:
        table_preservation = trans_table_rows / orig_table_rows
        if table_preservation < 0.9:
            quality_score -= 15
            issues.append(f"–ù–∞—Ä—É—à–µ–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü: {table_preservation:.1%}")

    # 5. –†–∞–∑–º–µ—Ä
    size_ratio = len(translated) / max(len(original), 1)
    if size_ratio > 2.5 or size_ratio < 0.4:
        quality_score -= 10
        issues.append(f"–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤: {size_ratio:.2f}")

    # 6. –ß–∏—Å–ª–∞ —Å –µ–¥–∏–Ω–∏—Ü–∞–º–∏
    orig_numbers = re.findall(r'\d+(?:\.\d+)?(?:W|MHz|GB|TB|GHz|mm)', original)
    trans_numbers = re.findall(r'\d+(?:\.\d+)?(?:W|MHz|GB|TB|GHz|mm)', translated)
    if len(orig_numbers) != len(trans_numbers):
        quality_score -= 10
        issues.append("–ù–µ –≤—Å–µ —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")

    quality_score = max(0, quality_score)
    
    status = ("–û–¢–õ–ò–ß–ù–û" if quality_score >= 95 else
              "–•–û–†–û–®–û" if quality_score >= 85 else
              "–£–î–û–í–õ–ï–¢–í–û–†–ò–¢–ï–õ–¨–ù–û" if quality_score >= 70 else
              "–ü–õ–û–•–û")

    return {
        'quality_score': quality_score,
        'status': status,
        'issues': issues,
        'chinese_fragments': chinese_count,
        'thinking_count': thinking_count,
        'table_preservation': trans_table_rows / max(orig_table_rows, 1) if orig_table_rows > 0 else 1,
        'size_ratio': size_ratio
    }

# ==============================================
# üóÑÔ∏è –ö–≠–®–ò–†–û–í–ê–ù–ò–ï v2.0
# ==============================================

def get_cache_key(text: str, source_lang: str, target_lang: str) -> str:
    """–°–æ–∑–¥–∞–Ω–∏–µ –∫–ª—é—á–∞ –¥–ª—è –∫—ç—à–∞"""
    content = f"{source_lang}-{target_lang}-{text}"
    return hashlib.md5(content.encode()).hexdigest()[:16]

def get_cached_translation(text: str, source_lang: str, target_lang: str) -> Optional[str]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–∞ –∏–∑ –∫—ç—à–∞"""
    if not ENABLE_CACHING:
        return None
    cache_key = get_cache_key(text, source_lang, target_lang)
    return translation_cache.get(cache_key)

def cache_translation(text: str, source_lang: str, target_lang: str, translation: str):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–∞ –≤ –∫—ç—à"""
    if not ENABLE_CACHING or len(translation_cache) >= CACHE_SIZE_LIMIT:
        return
    cache_key = get_cache_key(text, source_lang, target_lang)
    translation_cache[cache_key] = translation

# ==============================================
# üîó vLLM API –ö–õ–ò–ï–ù–¢ v2.0 (–ò–°–ü–†–ê–í–õ–ï–ù–û)
# ==============================================

class VLLMAPIClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å vLLM API"""

    def __init__(self):
        self.session = requests.Session()
        self.session.timeout = REQUEST_TIMEOUT
        
    async def enhanced_api_request(self, messages: List[Dict], timeout: int = REQUEST_TIMEOUT) -> Optional[str]:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∫ vLLM API"""
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ payload –¥–ª—è vLLM OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º–æ–≥–æ API
            payload = {
                "model": TRANSLATION_MODEL,
                "messages": messages,
                "temperature": API_TEMPERATURE,
                "max_tokens": API_MAX_TOKENS,
                "top_p": API_TOP_P,
                "stream": False
            }

            # –û—Ç–∫–ª—é—á–µ–Ω–∏–µ thinking —Ä–µ–∂–∏–º–∞ –¥–ª—è Qwen3
            if DISABLE_THINKING and "qwen" in TRANSLATION_MODEL.lower():
                if messages and messages[0]["role"] == "system":
                    messages[0]["content"] += "\n\nIMPORTANT: Respond directly without thinking process. No tags."

            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=timeout)) as session:
                async with session.post(
                    VLLM_API_URL + VLLM_API_ENDPOINT,
                    json=payload
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        if "choices" in result and len(result["choices"]) > 0:
                            translation_requests.inc()
                            return result["choices"][0]["message"]["content"]
                    else:
                        logger.error(f"vLLM API error: {response.status}")
                        
        except asyncio.TimeoutError:
            logger.warning("–¢–∞–π–º–∞—É—Ç vLLM API –∑–∞–ø—Ä–æ—Å–∞")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ vLLM API: {e}")
        
        return None

    async def translate_single(self, text: str, source_lang: str, target_lang: str, stats: TranslationStats) -> str:
        """–ü–µ—Ä–µ–≤–æ–¥ –æ–¥–Ω–æ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cached_result = get_cached_translation(text, source_lang, target_lang)
        if cached_result:
            stats.cache_hits += 1
            cache_hit_ratio.set(stats.cache_hits / (stats.cache_hits + stats.cache_misses))
            return cached_result

        stats.cache_misses += 1

        if not text.strip():
            return text

        source_name = get_language_name(source_lang)
        target_name = get_language_name(target_lang)

        # –°–æ–∑–¥–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
        system_prompt = get_system_prompt(source_name, target_name)
        user_prompt = get_user_prompt(text.strip(), source_name, target_name)

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç vLLM API
        response = await self.enhanced_api_request(messages)

        if response is None:
            return text

        # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞
        cleaned = self._postprocess_translation(response, target_lang, stats)

        # –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞
        validation = stats.add_quality_check(text, cleaned, target_lang)
        translation_quality.set(stats.get_average_quality())

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
        cache_translation(text, source_lang, target_lang, cleaned)

        # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
        await asyncio.sleep(INTER_REQUEST_DELAY)

        return cleaned

    def _postprocess_translation(self, response: str, target_lang: str, stats: TranslationStats) -> str:
        """–ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ —Å –æ—á–∏—Å—Ç–∫–æ–π thinking —Ä–µ–∂–∏–º–∞"""
        if not response:
            return ""

        # –ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞
        cleaned = response.strip()

        # –£–¥–∞–ª—è–µ–º thinking —Ç–µ–≥–∏ –∏ —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏—è
        thinking_patterns = [
            r'<–¥—É–º–∞—é>.*?</–¥—É–º–∞—é>',
            r'<thinking>.*?</thinking>',
            r'[–•—Ö]–æ—Ä–æ—à–æ[,\s]*–º–Ω–µ –Ω—É–∂–Ω–æ[^.]*?\.',
            r'[–°—Å]–Ω–∞—á–∞–ª–∞ –ø–æ—Å–º–æ—Ç—Ä[^.]*?\.',
            r'Let me[^.]*?\.',
            r'First[,\s]*I[^.]*?\.',
            r'[–í–≤]–æ—Ç –ø–µ—Ä–µ–≤–æ–¥[^:]*:?\s*',
            r'Here is[^:]*:?\s*',
            r'[–ù–Ω]–∏–∂–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω[^:]*:?\s*'
        ]

        for pattern in thinking_patterns:
            cleaned = re.sub(pattern, '', cleaned, flags=re.IGNORECASE | re.DOTALL)

        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã
        cleaned = self._fix_technical_terms(cleaned, target_lang, stats)

        # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞
        cleaned = re.sub(r'\n\s*\n\s*\n+', '\n\n', cleaned)
        cleaned = cleaned.strip()

        return cleaned

    def _fix_technical_terms(self, text: str, target_lang: str, stats: TranslationStats) -> str:
        """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤"""
        fixes_made = 0

        # –í–ê–ñ–ù–û: –ù–ï –ú–ï–ù–Ø–¢–¨ WenTian –Ω–∞ ThinkSystem!
        brand_fixes = {
            r'\b[Qq]itian\b': 'WenTian',
            r'\bSkyland\b': 'WenTian', 
            r'\bSkyStorage\b': 'WenTian'
        }

        for wrong_pattern, correct in brand_fixes.items():
            if re.search(wrong_pattern, text):
                text = re.sub(wrong_pattern, correct, text)
                fixes_made += 1

        # –í—ã–±–æ—Ä —Å–ª–æ–≤–∞—Ä—è —Ç–µ—Ä–º–∏–Ω–æ–≤
        if target_lang == "ru":
            terminology = TECHNICAL_TERMINOLOGY_RU
        else:
            terminology = TECHNICAL_TERMINOLOGY

        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
        for chinese_term, translation in terminology.items():
            if chinese_term in text:
                text = text.replace(chinese_term, translation)
                fixes_made += 1

        stats.technical_terms_fixed += fixes_made
        return text

def get_language_name(lang_code: str) -> str:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –∏–º–µ–Ω–∏ —è–∑—ã–∫–∞"""
    languages = {
        "zh-CN": "–∫–∏—Ç–∞–π—Å–∫–∏–π",
        "zh": "–∫–∏—Ç–∞–π—Å–∫–∏–π", 
        "ru": "—Ä—É—Å—Å–∫–∏–π",
        "en": "–∞–Ω–≥–ª–∏–π—Å–∫–∏–π"
    }
    return languages.get(lang_code, lang_code)

# ==============================================
# üéØ –ê–ù–ê–õ–ò–ó –ö–û–ù–¢–ï–ù–¢–ê v2.0
# ==============================================

def analyze_content_complexity(text: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
    if not text.strip():
        return 'empty'

    lines = text.strip().split('\n')

    # –ó–∞–≥–æ–ª–æ–≤–∫–∏
    if any(line.strip().startswith('#') for line in lines):
        return 'header'

    # –¢–∞–±–ª–∏—Ü—ã
    table_lines = [line for line in lines if line.strip().startswith('|')]
    if table_lines:
        max_cols = max(line.count('|') for line in table_lines)
        if max_cols > 6:
            return 'complex_table'
        elif len(table_lines) > 5:
            return 'table'

    # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
    if any(re.search(r'\d+\s*(GB|MB|GHz|MHz|W|TB)', line) for line in lines):
        return 'technical_specs'

    # –ö–æ–º–∞–Ω–¥—ã –∏ –∫–æ–¥—ã
    if any(re.search(r'\b(ipmitool|chassis|power|0x[0-9a-f]+)\b', line, re.I) for line in lines):
        return 'commands'

    # –°–º–µ—à–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
    if len(lines) > 3 and any('|' in line for line in lines):
        return 'mixed'

    return 'text'

def get_optimal_batch_size(content_type: str) -> int:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞"""
    batch_mapping = {
        'empty': 20,
        'header': BATCH_SIZE_HEADERS,
        'table': BATCH_SIZE_TABLES,
        'complex_table': 1,
        'technical_specs': 3,
        'commands': BATCH_SIZE_COMMANDS,
        'mixed': BATCH_SIZE_MIXED,
        'text': BATCH_SIZE_TEXT
    }
    return batch_mapping.get(content_type, BATCH_SIZE_TEXT)

# ==============================================
# üöÄ –û–°–ù–û–í–ù–û–ô –ü–ï–†–ï–í–û–î–ß–ò–ö v2.0
# ==============================================

async def vllm_translate(text: str, source_lang: str = "zh-CN", target_lang: str = "ru") -> Dict:
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–µ—Ä–µ–≤–æ–¥–∞ —Å vLLM"""
    logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ vLLM Translator v2.0")
    logger.info(f"üåê {source_lang} ‚Üí {target_lang}")
    logger.info(f"ü§ñ –ú–æ–¥–µ–ª—å: {TRANSLATION_MODEL}")
    logger.info(f"üß† Thinking –æ—Ç–∫–ª—é—á–µ–Ω: {DISABLE_THINKING}")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    client = VLLMAPIClient()
    stats = TranslationStats()
    
    lines = text.replace('\r\n', '\n').replace('\r', '\n').split('\n')
    stats.total_lines = len(lines)

    # –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    content_analysis = {}
    for line in lines:
        content_type = analyze_content_complexity(line)
        content_analysis[content_type] = content_analysis.get(content_type, 0) + 1

    logger.info("üìä –ê–ù–ê–õ–ò–ó –ö–û–ù–¢–ï–ù–¢–ê:")
    for content_type, count in content_analysis.items():
        logger.info(f"  {content_type}: {count} —Å—Ç—Ä–æ–∫")

    translated_lines = []
    
    # –ë–∞—Ç—á–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
    i = 0
    with translation_duration.time():
        while i < len(lines):
            line = lines[i]
            if not line.strip():
                translated_lines.append(line)
                i += 1
                continue

            content_type = analyze_content_complexity(line)
            batch_size = get_optimal_batch_size(content_type)

            # –°–æ–∑–¥–∞–µ–º –±–∞—Ç—á
            batch_lines = []
            for j in range(i, min(i + batch_size, len(lines))):
                if j < len(lines) and lines[j].strip():
                    batch_lines.append(lines[j])

            if batch_lines:
                if len(batch_lines) == 1:
                    # –û–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞
                    translated = await client.translate_single(batch_lines[0], source_lang, target_lang, stats)
                    translated_lines.append(translated)
                else:
                    # –ù–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫ - –æ–±—ä–µ–¥–∏–Ω—è–µ–º –≤ –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å
                    batch_text = '\n'.join(batch_lines)
                    translated_batch = await client.translate_single(batch_text, source_lang, target_lang, stats)
                    
                    # –†–∞–∑–±–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞—Ç–Ω–æ
                    batch_result_lines = translated_batch.split('\n')
                    if len(batch_result_lines) == len(batch_lines):
                        translated_lines.extend(batch_result_lines)
                    else:
                        # –ï—Å–ª–∏ —Ä–∞–∑–±–∏–≤–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å, –ø–µ—Ä–µ–≤–æ–¥–∏–º –ø–æ –æ–¥–Ω–æ–π
                        for single_line in batch_lines:
                            single_translated = await client.translate_single(single_line, source_lang, target_lang, stats)
                            translated_lines.append(single_translated)

                i += len(batch_lines)
            else:
                i += 1

    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    result = '\n'.join(translated_lines)

    # –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
    final_validation = validate_technical_translation(text, result, target_lang)
    logger.info(f"üìä –§–ò–ù–ê–õ–¨–ù–ê–Ø –í–ê–õ–ò–î–ê–¶–ò–Ø: {final_validation['quality_score']:.1f}/100")

    if final_validation['issues']:
        logger.warning("‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã:")
        for issue in final_validation['issues']:
            logger.warning(f"  - {issue}")

    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—Å—Ç–∞—Ç–∫–æ–≤ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    stats.chinese_remaining_start = len(re.findall(r'[\u4e00-\u9fff]', result))
    if stats.chinese_remaining_start > 0:
        logger.info(f"üîß –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {stats.chinese_remaining_start} –∫–∏—Ç–∞–π—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤, –∑–∞–ø—É—Å–∫–∞–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ...")
        result = await intelligent_fix_remaining(result, source_lang, target_lang, client, stats)
    
    stats.chinese_remaining_end = len(re.findall(r'[\u4e00-\u9fff]', result))
    stats.processing_time = time.time() - stats.start_time

    return {
        'translated_content': result,
        'stats': {
            'total_lines': stats.total_lines,
            'api_requests': stats.api_requests,
            'cache_hits': stats.cache_hits,
            'cache_misses': stats.cache_misses,
            'chinese_remaining': stats.chinese_remaining_end,
            'processing_time': stats.processing_time,
            'average_quality': stats.get_average_quality(),
            'fixes_applied': stats.fixes_successful
        },
        'quality_score': final_validation['quality_score']
    }

async def intelligent_fix_remaining(text: str, source_lang: str, target_lang: str, client: VLLMAPIClient, stats: TranslationStats) -> str:
    """–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –∫–∏—Ç–∞–π—Å–∫–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤"""
    logger.info("üîß –ò–ù–¢–ï–õ–õ–ï–ö–¢–£–ê–õ–¨–ù–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï v2.0")

    # –ù–∞—Ö–æ–¥–∏–º –∫–∏—Ç–∞–π—Å–∫–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã
    chinese_fragments = []
    for match in re.finditer(r'[\u4e00-\u9fff]+', text):
        fragment = match.group()
        if len(fragment) >= 2:
            chinese_fragments.append((fragment, match.span()))

    if not chinese_fragments:
        logger.info("‚úÖ –ö–∏—Ç–∞–π—Å–∫–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        return text

    logger.info(f"üá®üá≥ –ù–∞–π–¥–µ–Ω–æ {len(chinese_fragments)} –∫–∏—Ç–∞–π—Å–∫–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")

    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π
    fragments_to_fix = chinese_fragments[:10]  # –ú–∞–∫—Å–∏–º—É–º 10
    current_text = text
    fixes_count = 0

    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ –æ–¥–Ω–æ–º—É —Ñ—Ä–∞–≥–º–µ–Ω—Ç—É
    for fragment, span in fragments_to_fix:
        stats.fixes_attempted += 1

        translated = await client.translate_single(fragment, source_lang, target_lang, stats)
        
        if translated and fragment != translated and not re.search(r'[\u4e00-\u9fff]', translated):
            current_text = current_text.replace(fragment, translated, 1)
            stats.fixes_successful += 1
            fixes_count += 1
            logger.info(f"‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω #{fixes_count}: {fragment} ‚Üí {translated[:20]}...")

    final_fragments = len(re.findall(r'[\u4e00-\u9fff]', current_text))
    improvement = len(chinese_fragments) - final_fragments

    logger.info("üìà –†–ï–ó–£–õ–¨–¢–ê–¢ –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø:")
    logger.info(f"  –ë—ã–ª–æ: {len(chinese_fragments)}")
    logger.info(f"  –°—Ç–∞–ª–æ: {final_fragments}")
    logger.info(f"  –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: {improvement}")

    return current_text

# ==============================================
# üåê FASTAPI –°–ï–†–í–ï–† v2.0
# ==============================================

# Pydantic –º–æ–¥–µ–ª–∏
class TranslationRequest(BaseModel):
    text: str
    source_lang: str = "zh-CN"
    target_lang: str = "ru"

class TranslationResponse(BaseModel):
    translated_content: str
    stats: Dict
    quality_score: float
    processing_time: float

# FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = FastAPI(
    title="vLLM Translator Service v2.0",
    description="–í—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å vLLM",
    version="2.0.0"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    """Root endpoint"""
    return {
        "service": "vLLM Translator Service v2.0",
        "status": "running",
        "model": TRANSLATION_MODEL,
        "thinking_disabled": DISABLE_THINKING
    }

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "service": "vLLM Translator v2.0",
        "timestamp": datetime.now().isoformat(),
        "cache_size": len(translation_cache),
        "cache_limit": CACHE_SIZE_LIMIT
    }

@app.post("/api/v1/translate", response_model=TranslationResponse)
async def translate_text(request: TranslationRequest) -> TranslationResponse:
    """–û—Å–Ω–æ–≤–Ω–æ–π endpoint –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞"""
    try:
        start_time = time.time()
        
        result = await vllm_translate(
            text=request.text,
            source_lang=request.source_lang,
            target_lang=request.target_lang
        )
        
        processing_time = time.time() - start_time
        
        return TranslationResponse(
            translated_content=result['translated_content'],
            stats=result['stats'],
            quality_score=result['quality_score'],
            processing_time=processing_time
        )
        
    except Exception as e:
        logger.error(f"Translation error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/stats")
async def get_translation_stats():
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–µ—Ä–≤–∏—Å–∞"""
    return {
        "cache_size": len(translation_cache),
        "cache_limit": CACHE_SIZE_LIMIT,
        "cache_hit_ratio": cache_hit_ratio._value.get() if cache_hit_ratio._value else 0,
        "total_requests": translation_requests._value.get(),
        "average_quality": translation_quality._value.get() if translation_quality._value else 0,
        "model": TRANSLATION_MODEL,
        "thinking_disabled": DISABLE_THINKING
    }

@app.get("/metrics")
async def metrics():
    """Prometheus –º–µ—Ç—Ä–∏–∫–∏"""
    return prometheus_client.generate_latest()

# ==============================================
# üíé –ó–ê–ü–£–°–ö –°–ï–†–í–ï–†–ê
# ==============================================

if __name__ == "__main__":
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=int(os.getenv('SERVICE_PORT', '8003')),
        workers=1,
        log_level="info"
    )